---
# This Ansible Playbook show how to add an Anarchy Subject through a Poolboy
- name: Babylon Integration
  hosts: localhost
  gather_facts: false
  vars:
    # Vars to override as extra-vars
    account: CHANGEME
    catalog_item: CHANGEME
    catalog_stage: CHANGE ME dev|test|prod
    catalog_item_params_file: CHANGEME
    kubeconfig: CHANGEME
    platform: CHANGEME
    cloudforms_username: CHANGEME

    # After that don't touch
    user_namespace: user-{{ cloudforms_username | replace('_', '-') | replace('.', '-') }}
    catalog_item_name: "{{ account | replace('_', '-') }}.{{ catalog_item | lower | regex_replace('_', '-') }}.{{ catalog_stage }}"
    platform_url: "{% if 'OPENTLC' in platform %}https://labs.opentlc.com/{% else %}https://rhpds.redhat.com/{% endif %}"

  tasks:
  - name: Git minimal facts
    ansible.builtin.setup:
      gather_subset: min

  - name: Include vars
    include_vars:
      file: "{{ catalog_item_params_file }}"
      name: catalog_item_params

  - name: Show catalog_item_params
    debug:
      var: vars.catalog_item_params
      verbosity: 2

  - name: Check that guid is set in catalog_item_params
    fail:
      msg: guid must be defined in catalog_item_params
    when: >-
      "guid" not in vars.catalog_item_params
      or vars.catalog_item_params.guid == ''

  - name: Check that uuid is set in catalog_item_params
    fail:
      msg: uuid must be defined in catalog_item_params
    when: >-
      "uuid" not in vars.catalog_item_params
      or vars.catalog_item_params.uuid == ''

  - name: Set vars from catalog_item_params
    set_fact:
      anarchy_namespace: >-
        {{ vars.catalog_item_params.__meta__.anarchy.namespace | default('anarchy-operator') }}
      guid: >-
        {{ vars.catalog_item_params.guid }}
      uuid: >-
        {{ vars.catalog_item_params.uuid }}
      # Take cloud_tags, but drop values to ignore, guid and uuid
      cloud_tags: >-
        {{ vars.catalog_item_params.cloud_tags | default('{}') | from_yaml
         | dict2items | json_query("[?key!='guid' && key!='uuid']") | items2dict }}
      resource_claim_name: >-
        {{ catalog_item_name }}-{{ vars.catalog_item_params.guid }}

  - block:
    - name: Wait for AnarchyGovernor {{ catalog_item_name }} vars sync
      k8s_info:
        kubeconfig: "{{ kubeconfig }}"
        api_version: anarchy.gpte.redhat.com/v1
        kind: AnarchyGovernor
        namespace: "{{ anarchy_namespace }}"
        name: "{{ catalog_item_name }}"
      register: r_governor
      vars:
        # Check AnarchyGovernor vars that are not listed in params_to_variables
        check_governor_job_vars: >-
          {{ r_governor.resources[0].spec.vars.job_vars
           | default({})
           | dict2items
           | json_query(filter_var_query)
           | items2dict
          }}
        filter_var_query: >-
          [?!contains(`{{ filter_var_list | to_json }}`, key)]
        filter_var_list: >-
          {{ (vars.catalog_item_params.agnosticv_meta.params_to_variables | default({})).values() | list
           + ["agnosticv_meta"] }}
      failed_when: >-
        r_governor.resources | length == 0 or
        vars.catalog_item_params != vars.catalog_item_params | combine(check_governor_job_vars)
      until: r_governor is success
      delay: 5
      retries: 60
    rescue:
    - name: Report failure waiting for AnarchyGovernor vars sync
      fail:
        msg: |-
         {% if r_governor.resources | length == 0 %}
         AnarchyGovernor {{ catalog_item_name }} not found in {{ anarchy_namespace }} namespace.
         {% else %}
         AnarchyGovernor {{ catalog_item_name }} in {{ anarchy_namespace }} job_vars do not match agnosticv.
         {% endif %}
         Check agnosticv-operator logs:
           oc logs -n agnosticv-operator deployment/agnosticv-operator

  - name: Create namespace for {{ cloudforms_username }}
    k8s:
      kubeconfig: "{{ kubeconfig }}"
      definition:
        apiVersion: v1
        kind: Namespace
        metadata:
          annotations:
            openshift.io/description: User Namespace for {{ cloudforms_username }}
            openshift.io/display-name: "{{ user_namespace }}"
            openshift.io/requester: "{{ cloudforms_username }}"
          name: "{{ user_namespace }}"

  - name: Grant babylon-user-service-access for {{ cloudforms_username }} in namespace
    k8s:
      kubeconfig: "{{ kubeconfig }}"
      definition:
        apiVersion: rbac.authorization.k8s.io/v1
        kind: RoleBinding
        metadata:
          name: babylon-user-service-access:{{ cloudforms_username }}
          namespace: "{{ user_namespace }}"
        roleRef:
          apiGroup: rbac.authorization.k8s.io
          kind: ClusterRole
          name: babylon-user-service-access
        subjects:
        - apiGroup: rbac.authorization.k8s.io
          kind: User
          name: "{{ cloudforms_username }}"

  - name: Create ResourceClaim {{ resource_claim_name }}
    vars:
      __meta_catalog_parameter_names: >-
        {{ vars.catalog_item_params | json_query('__meta__.catalog.parameters[].name') }}
      __job_vars_from_configured_parameters: >-
        {{ vars.catalog_item_params | dict2items
         | json_query("[?contains(`" ~ __meta_catalog_parameter_names | to_json ~ "`, key)]")
         | items2dict | combine({"cloud_tags": vars.cloud_tags} if 'cloud_tags' in __meta_catalog_parameter_names else {}) }}
      __job_vars_all: >-
        {{ vars.catalog_item_params | dict2items
         | json_query("[?key!='guid' && key!='uuid' && key!='cloud_tags']")
         | items2dict | combine({"cloud_tags": vars.cloud_tags}) }}
      # Resource definition for common ResourceProvider
      __babylon_provider_resource_item:
        provider:
          apiVersion: poolboy.gpte.redhat.com/v1
          kind: ResourceProvider
          name: babylon
          namespace: poolboy
        template:
          apiVersion: anarchy.gpte.redhat.com/v1
          kind: AnarchySubject
          metadata:
            annotations:
              poolboy.gpte.redhat.com/resource-provider-name: babylon
              poolboy.gpte.redhat.com/resource-provider-namespace: poolboy
            generateName: "{{ catalog_item_name }}-"
          spec:
            governor: "{{ catalog_item_name }}"
            vars:
              # Indicate that environment should start if match to a stopped environment
              desired_state: started
              # Set job_vars, excluding "guid" and "uuid" and insert filtered "cloud_tags"
              job_vars: >-
                {% if __meta_catalog_parameter_names != '' -%}
                {{ __job_vars_from_configured_parameters }}
                {%- else -%}
                {{ __job_vars_all }}
                {%- endif %}
      # Resource definition to use when ResourceProvider is specific to the AgnosticV item
      __provider_specific_resource_item:
        provider:
          apiVersion: poolboy.gpte.redhat.com/v1
          kind: ResourceProvider
          name: "{{ catalog_item_name }}"
          namespace: poolboy
        template:
          spec:
            vars:
              job_vars: "{{ __job_vars_from_configured_parameters }}"
    k8s:
      kubeconfig: "{{ kubeconfig }}"
      definition:
        apiVersion: poolboy.gpte.redhat.com/v1
        kind: ResourceClaim
        metadata:
          name: "{{ resource_claim_name }}"
          namespace: "{{ user_namespace }}"
          annotations:
            # Link which should be used from the catalog UI to CloudForms
            babylon.gpte.redhat.com/externalPlatformUrl: "{{ platform_url }}"
            # Only CloudForms should notify regarding events from
            babylon.gpte.redhat.com/notifier: disable
            # Requester annotation directly on the ResourceClaim is more
            # convenient than looking up from the namespace.
            babylon.gpte.redhat.com/requester: "{{ cloudforms_username }}"
          labels:
            uuid: "{{ uuid }}"
        spec:
          resources:
          - >-
            {%- if vars.catalog_item_params.__meta__.anarchy.namespace is defined -%}
            {{ __provider_specific_resource_item }}
            {%- else -%}
            {{ __babylon_provider_resource_item }}
            {%- endif -%}
    register: r_create_resource_claim

  - name: Report ResourceClaim
    debug:
      msg: "babylon.resourceClaim: {{ user_namespace }} {{ resource_claim_name }}"

  - block:
    - name: Wait for ResourceHandle to be assigned to ResourceClaim {{ resource_claim_name }}
      k8s_info:
        kubeconfig: "{{ kubeconfig }}"
        api_version: poolboy.gpte.redhat.com/v1
        kind: ResourceClaim
        namespace: "{{ user_namespace }}"
        name: "{{ resource_claim_name }}"
      register: r_claim
      retries: 60
      delay: 5
      until: >-
        'resourceHandle' in r_claim.resources[0].status | default({})
    rescue:
    - name: Report failure waiting for ResourceHandle
      fail:
        msg: |-
         No ResourceHandle assigned to ResourceClaim {{ resource_claim_name }} in project namespace {{ user_namespace }}.
         Check poolboy logs:
           oc logs -n poolboy deployment/poolboy | fgrep {{ resource_claim_name }}

  - name: Set fact for ResourceClaim and ResourceHandle name
    set_fact:
      resource_claim: "{{ r_claim.resources[0] }}"
      resource_handle_name: "{{ r_claim.resources[0].status.resourceHandle.name }}"

  - name: Report ResourceHandle
    debug:
      msg: "babylon.resourceHandle: {{ resource_handle_name }}"

  - name: Get ResourceHandle
    k8s_info:
      kubeconfig: "{{ kubeconfig }}"
      api_version: poolboy.gpte.redhat.com/v1
      kind: ResourceHandle
      namespace: poolboy
      name: "{{ resource_handle_name }}"
    register: r_get_resource_handle
    failed_when: r_get_resource_handle.resources | length != 1

  - name: Set fact for ResourceHandle
    set_fact:
      resource_handle: "{{ r_get_resource_handle.resources[0] }}"

  - name: Override lifespan and stop configuration
    when: >-
      'lifespan' in resource_handle.spec
    block:
    - name: Override lifespan and runtime in ResourceHandle
      vars:
        __resource_item_patch:
          template:
            spec:
              vars:
                action_schedule:
                  maximum_runtime: 1000d
                  stop: "{{ '%FT%TZ' | strftime(500 * 24 * 60 * 60 + ansible_date_time.epoch | int) }}"
      k8s:
        kubeconfig: "{{ kubeconfig }}"
        definition:
          apiVersion: poolboy.gpte.redhat.com/v1
          kind: ResourceHandle
          metadata:
            name: "{{ resource_handle_name }}"
            namespace: poolboy
          spec:
            lifespan:
              maximum: 500d
              relativeMaximum: 500d
            resourceClaim: "{{ resource_handle.spec.resourceClaim }}"
            resources:
            - >-
              {{ resource_claim.spec.resources[0] | combine(__resource_item_patch) }}

    - name: Override lifespan and runtime in ResourceClaim
      vars:
        __resource_item_patch:
          template:
            spec:
              vars:
                action_schedule:
                  start: "{{ ansible_date_time.iso8601 }}"
                  stop: "{{ '%FT%TZ' | strftime(500 * 24 * 60 * 60 + ansible_date_time.epoch | int) }}"
      k8s:
        kubeconfig: "{{ kubeconfig }}"
        definition:
          apiVersion: poolboy.gpte.redhat.com/v1
          kind: ResourceClaim
          metadata:
            name: "{{ resource_claim_name }}"
            namespace: "{{ user_namespace }}"
          spec:
            lifespan:
              end: "{{ '%FT%TZ' | strftime(1000 * 24 * 60 * 60 + ansible_date_time.epoch | int) }}"
            resources:
            - >-
              {{ resource_handle.spec.resources[0] | combine(__resource_item_patch) }}

  - block:
    - name: Wait for AnarchySubject to appear in ResourceClaim {{ resource_claim_name }} status
      k8s_info:
        kubeconfig: "{{ kubeconfig }}"
        api_version: poolboy.gpte.redhat.com/v1
        kind: ResourceClaim
        namespace: "{{ user_namespace }}"
        name: "{{ resource_claim_name }}"
      register: r_claim
      retries: 60
      delay: 5
      until: >-
        'state' in r_claim.resources[0].status.resources[0] | default({})
    rescue:
    - name: Report failure waiting for AnarchySubject
      fail:
        msg: |-
          No AnarchySubject created for ResourceHandle {{ r_claim.resources[0].status.resourceHandle.name }}.
          Check poolboy logs:
            oc logs -n poolboy deployment/poolboy | fgrep {{ r_claim.resources[0].status.resourceHandle.name }}

  - name: Set anarchy_subject_name
    set_fact:
      anarchy_subject_name: "{{ r_claim.resources[0].status.resources[0].state.metadata.name }}"

  - name: Report AnarchySubject
    debug:
      msg: "babylon.anarchySubject: {{ anarchy_subject_name }}"

  - block:
    - name: Wait for AnarchySubject current_state to be updated in the ResourceClaim
      k8s_info:
        kubeconfig: "{{ kubeconfig }}"
        api_version: poolboy.gpte.redhat.com/v1
        kind: ResourceClaim
        namespace: "{{ user_namespace }}"
        name: "{{ resource_claim_name }}"
      register: r_claim
      retries: 60
      delay: 5
      until: >-
        'current_state' in r_claim.resources[0].status.resources[0].state.spec.vars | default({})
    rescue:
    - name: Report failure waiting for AnarchySubject current_state
      fail:
        msg: |-
          AnarchySubject {{ anarchy_subject_name }} has not been handled by Anarchy.
          {% if __anarchy_subject.status.runStatus | default('') != '' %}
          Run status {{ __anarchy_subject.status.runStatus }}: {{ __anarchy_subject.status.runStatusMessage | default("no message") }}
          {% else %}
          Check anarchy logs:
            oc logs -n {{ anarchy_namespace }} deployment/anarchy | fgrep {{ anarchy_subject_name }}
          Check for problems with AnarchyRun to process create of AnarchySubject:
            oc get anarchyruns -n {{ anarchy_namespace }} -l anarchy.gpte.redhat.com/subject={{ anarchy_subject_name }}
          {% endif %}
      vars:
        __anarchy_subject: "{{ r_claim.resources[0].status.resources[0].state | default({}) }}"

  - name: Report current state
    debug:
      msg: "babylon.currentState: {{ r_claim.resources[0].status.resources[0].state.spec.vars.current_state }}"

  - name: Report babylon assigned GUID
    debug:
      msg: "babylon.guid: {{ r_claim.resources[0].status.resources[0].state.spec.vars.job_vars.guid }}"

  - name: Report babylon assigned UUID
    debug:
      msg: "babylon.uuid: {{ r_claim.resources[0].status.resources[0].state.spec.vars.job_vars.uuid }}"

  - block:
    - name: Wait for AnarchySubject state provisioning or subsequent states to be updated in the ResourceClaim
      k8s_info:
        kubeconfig: "{{ kubeconfig }}"
        api_version: poolboy.gpte.redhat.com/v1
        kind: ResourceClaim
        namespace: "{{ user_namespace }}"
        name: "{{ resource_claim_name }}"
      register: r_claim
      retries: 120
      delay: 5
      vars:
        __subject: "{{ r_claim.resources[0].status.resources[0].state }}"
      until: >-
        __subject.spec.vars.current_state | default('') in ['provisioning', 'started', 'starting', 'stopping', 'stopped']
        and
        __subject.status.towerJobs.provision.deployerJob | default('') != ''

    rescue:
    - name: Report failure waiting for provisioning state
      fail:
        msg: |-
          AnarchySubject {{ anarchy_subject_name }} has not moved to current_state of provisioning.
          {% if __anarchy_subject.status.runStatus | default('') != '' %}
          Run status {{ __anarchy_subject.status.runStatus }}: {{ __anarchy_subject.status.runStatusMessage | default("no message") }}
          {% else %}
          Check AnarchyRuns to see if there was an issue starting the job:
            oc get anarchyruns -n {{ anarchy_namespace }} -l anarchy.gpte.redhat.com/subject={{ anarchy_subject_name }}
          {% endif %}
      vars:
        __anarchy_subject: "{{ r_claim.resources[0].status.resources[0].state | default({}) }}"

  - name: Report current state
    debug:
      msg: >-
        babylon.currentState:
        {{ r_claim.resources[0].status.resources[0].state.spec.vars.current_state }}

  - name: Get Tower credentials and access information
    k8s_info:
      kubeconfig: "{{ kubeconfig }}"
      api_version: v1
      kind: Secret
      namespace: "{{ anarchy_namespace }}"
      name: babylon-tower
    register: r_babylon_tower_secret

  - name: Fail if babylon-tower secret not found
    fail:
      msg: "babylon-tower secret not found"
    when: r_babylon_tower_secret.resources | length == 0

  - name: Create output_dir/secrets
    file:
      path: "{{ output_dir }}/secrets"
      state: directory
      mode: u=rwx,go=

  - name: Write tower information to yaml file
    vars:
      babylon_tower_secret: "{{ r_babylon_tower_secret.resources[0] }}"
      tower_hostname: "{{ babylon_tower_secret.data.hostname | b64decode }}"
      tower_user: "{{ babylon_tower_secret.data.user | b64decode }}"
      tower_password: "{{ babylon_tower_secret.data.password | b64decode }}"
      tower_job: >-
        {{ r_claim.resources[0].status.resources[0].state.status.towerJobs.provision.deployerJob }}
    copy:
      dest: "{{ output_dir }}/secrets/tower.rc"
      content: |
        export TOWER_HOST={{ ("https://" ~ tower_hostname) | quote }}
        export TOWER_VERIFY_SSL=false
        export TOWER_USERNAME={{ tower_user | quote }}
        export TOWER_PASSWORD={{ tower_password | quote }}
        export TOWER_JOB={{ tower_job | quote }}
